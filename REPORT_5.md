# Домашнее задание к уроку 5: Аугментации и работа с изображениями

## Датасет

Используйте датасет с изображениями героев, структура папок:
```
data/
├── train/
│   ├── hero1/
│   │   ├── image1.jpg
│   │   └── ...
│   ├── hero2/
│   │   └── ...
│   └── ...
├── val/
│   └── ...
└── test/
    └── ...
```

Для загрузки используйте класс `CustomImageDataset` из `datasets.py`.

---

## Задание 1: Стандартные аугментации torchvision (15 баллов)

1. Создайте пайплайн стандартных аугментаций torchvision (например, RandomHorizontalFlip, RandomCrop, ColorJitter, RandomRotation, RandomGrayscale).
2. Примените аугментации к 5 изображениям из разных классов (папка train).
3. Визуализируйте:
   - Оригинал
   - Результат применения каждой аугментации отдельно
   - Результат применения всех аугментаций вместе

---
### Загрузил данные из google drive + DataLoader
### Использовал класс CustomImageDataset для работы  для работы с папками классов с урока
### Использовал 5 аугментаций из torchvivsion (RandomHorizontalFlip, RandomResizedCrop, ColorJitter, RandomRotation, RandomGrayscale) и все вместе
![5_1_Classic_Augmentations](https://github.com/MakarRybkin/Summer_practice_Deep_Learning/raw/master/plots_for_reports/5_1_Classic_Augmentations.png)
## Задание 2: Кастомные аугментации (20 баллов)

1. Реализуйте минимум 3 кастомные аугментации (например, случайное размытие, случайная перспектива, случайная яркость/контрастность).
2. Примените их к изображениям из train.
3. Сравните визуально с готовыми аугментациями из extra_augs.py.
### Реализовал 3 кастомные аугментации как предложено - случайное размытие, случайная перспектива, случайная яркость/контрастность, и применил их к 3 изображениям из train разных классов.
![5_2_Custom_augmentations](https://github.com/MakarRybkin/Summer_practice_Deep_Learning/raw/master/plots_for_reports/5_2_Custom_augmentations.png)

## Задание 3: Анализ датасета (10 баллов)

1. Подсчитайте количество изображений в каждом классе.
2. Найдите минимальный, максимальный и средний размеры изображений.
3. Визуализируйте распределение размеров и гистограмму по классам.

---
### В каждом из 6 классов в train оказалось по 30 изображений
### Минимальный размер изображения: 210x240
### Максимальный размер изображения: 736x1308
### Средний размер изображения: 538.9x623.6
### Визуализировал распределение размеров и гистограмму по классам.
![5_3_Sizes_of_images](https://github.com/MakarRybkin/Summer_practice_Deep_Learning/raw/master/plots_for_reports/5_3_Sizes_of_images.png)
### Как можно увидеть большинство изображений одного размера
## Задание 4: Pipeline аугментаций (20 баллов)

1. Реализуйте класс AugmentationPipeline с методами:
   - add_augmentation(name, aug)
   - remove_augmentation(name)
   - apply(image)
   - get_augmentations()
2. Создайте несколько конфигураций (light, medium, heavy).
3. Примените каждую конфигурацию к train и сохраните результаты.
### Реализовал класс AugmentationPipeline с нужными методами
### Light - только colorjitter, Medium - flip, rotate, colorjitter, heavy - medium +  BrightnessContrast, Blur с вероятностью 0.6
### Применил 3 пайплайна для первых 3 изображений из train и сохранил в папку augmented_results
## Задание 5: Эксперимент с размерами (10 баллов)

1. Проведите эксперимент с разными размерами изображений (например, 64x64, 128x128, 224x224, 512x512).
2. Для каждого размера измерьте время загрузки и применения аугментаций к 100 изображениям, а также потребление памяти.
3. Постройте графики зависимости времени и памяти от размера.

---
### Использовал memory_profiler для измерения памяти
### Написал функцию для предобработки изображений (transform , resize)
### в transform здесь использовал flip , rotation и colorjitter
### Использование времени и памяти для разных размеров:
![5_5_plots_for_time_and_memory](https://github.com/MakarRybkin/Summer_practice_Deep_Learning/raw/master/plots_for_reports/5_5_plots_for_time_and_memory.png)
### Как видно из графиков чем больше размер изображения, тем больше время обработки и требуемая память
## Задание 6: Дообучение предобученных моделей (25 баллов)

1. Возьмите одну из предобученных моделей torchvision (например, resnet18, efficientnet_b0, mobilenet_v3_small).
2. Замените последний слой на количество классов вашего датасета.
3. Дообучите модель на train, проверьте качество на val.
4. Визуализируйте процесс обучения (loss/accuracy)
### Загрузил train и test данные с трансформацией для Resnet18 IMAGENET1K_V1 и обучил эту модель https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html#torchvision.models.ResNet18_Weights
### Обучил на 15 эпохах с lr=1e-3
![5_6](https://github.com/MakarRybkin/Summer_practice_Deep_Learning/raw/master/plots_for_reports/5_6.png)
### Из-за того, что изображения довольно сильно отличаются (персонажи в разных позах, одежде с разным фоном) и я использовал не очень сложную модель на 15 эпохах получил accuracy = 0.8467, с сильно прыгающими метриками 
### Выводы:

### Аугментации:
### Проверил стандартные и кастомные аугментации, визуализации показали их эффективность для увеличения разнообразия данных.

### Анализ датасета:
### Изучил размеры изображений и количество примеров в классах — данные сбалансированы, но размеры сильно различаются.

### Pipeline аугментаций:
### Создал удобный класс для настройки цепочек аугментаций с разными уровнями интенсивности.

### Эксперимент с размерами:
### Подтвердил, что большие изображения сильно увеличивают время обработки и потребление памяти.

### Дообучение модели:
### Дообучил ResNet18, получил accuracy ~0.85 на тесте — хороший результат для базовой модели.